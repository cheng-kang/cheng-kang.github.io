---
title: 《Learning AV Foundation》学习笔记，第一章：AV Foundation 基础
date: 2017-06-06 19:20:16
tags:
- iOS
- AV Foundation
---

> 本系列是我学习《Learning AV Foundation：A Hands-on Guide to Matering the AV Foundation Framework》的学习笔记。将以章为单位，对内容进行总结。

## AV Foundation

AV Foundation 处于上层框架（iOS：AVKit、UIKit，Mac OS：AVKit、AppKit）和底层框架（Core Audio、Core Video，Core Media 以及 Core Animation）之间，在 iOS 和 Mac OS 中通用。

其主要功能包括：

- 音频播放和记录（Audio Playback and Recording）
- 媒体文件检查（Media Inspection）
- 视频播放（Video Playback）
- 媒体捕捉（Media Capture）
- 媒体编辑（Media Editing）
- 媒体处理（Media Processing）


## 数字媒体 （Digital Media）

现实中的信号是连续的，数字世界中的信号是离散的。为了储存并传输媒体信息，需要将将连续的`模拟信号`转换为离散的`数字信号`，这一过程称之为`采样（Sampling）`。

### 采样的两种方式

1. 时间采样（Temporal Sampling）：捕捉一个信号在周期内的变化。
2. 空间采样（Spatial Sampling)：对一幅图片在一定分辨率之下捕捉其亮度和色度，
进而创建由该图片的像素点数据所构成的数字化结果。

> 当对一段视频进行数字化时，这两种方式都可以使用，因为通常的视频信号既有空间属性又有时间属性。

### 音频采样

如下两个音频正弦波图，分别是 1Hz （左）和 5Hz （右）。

![]()

我们对信号的两个方面比较感兴趣。一个是`振幅`，它代表电压的强度或者对应信号的强度。另一个是`频率`（单位：赫兹 Hz），表示在一定周期内完成循环的次数。

> 人类可听见的音频范围是 20Hz~20kHz。但具体范围也因人而异。

音频数字化使用到一个编码方法，称为`线性脉冲编码调制（linear pulse-code madulation）`，也常被称为 `Linear PCM` 或者 `LPCM`。这个过程通过一个固定的周期率（`采样率（Sampling Rate）`）对音频信号进行采样。下图展示了在一秒内对信号进行 7 此采样及信号数字化的结果：

![]()

显然低`采样率`的数字信号无法很好地表现原始数据。下图是提高`采样率`之后的结果：

![]()

虽然无法完全准确表现原始信号，但是随着`采样率`的提高，我们可以找到一个能够生成足够好的数字呈现效果的`采样率`。这个`采样率`被称为`尼奎斯特率`。**Harry Nyquist 发现：想要准确地捕捉一个特定频率，你需要用至少两倍于其最高频率的`采样率`进行采样。**

数字音频采样另一个重要的方面是我们捕捉每个样本的准确度。因为`振幅`是线性衡量的，因此也就有了`线性脉冲编码调制`这个术语。“用于保存样本值的字节数定义了在线性维度上可行的离散度，同时这个信息也被称为音频的`位元深度(Bit Depth)`。为每个样本的整体量化分配过少的位结果信息会导致数字音频信号产生噪声和扭曲。使用`位元深度`为8的方法可以提供 256 个离散级别的数据，对于一些音频资源来说，这个级别的`采样率`已经足够了，但对于大部分音频内容来说还不够高。CD音质的`位元深度`为 16，可以达到 65536 个离散级别。专业级别的音频录制环境的`位元深度`可以达到 24 或更高。”

### 数字媒体压缩

视频文件由一系列被称为`帧（frame）`的图片组成。视频文件一秒钟内所能展现的帧数称为视频的`帧率`，并用 `FPS(frames per second)` 作为单位进行测量。常见的帧率是24FPS、25FPS 和 30FPS。以下是不同色彩空间、分辨率及帧率下未压缩视频占用空间打下：

![]()

显然，需要压缩。

视频数据通常用一个叫做 `Y'CbCr` 的颜色模型进行加密，其方法是分离色彩通道（UV）和亮度通道（Y）。



